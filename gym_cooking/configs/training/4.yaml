# command: python main.py --config training/2
# RunInfo:
run-id: MAPPO-4x3-FINAL
 # for identifying in logs and in folders etc
continue-run: false # continue training from previous run
notes: Training 4x3 layout with model trained on 4x3-FINAL
tags: 4x3, FINAL # comma separated list of tags for this run

# Environment:
level: open-divider_salad
num-agents: 4
num-orders: 3
max-num-timesteps: 200 # quit after this many timesteps
max-num-subtasks: 14
seed: 1
device: cuda
# Environment Switches
record: false
randomize: true

# Mode:
play: false
train: true
evaluate: false
sweep: false

# Agents:

# Training Parameters:
num-processes: 100 # number of parallel environments
# MAPPO and PPO
num-total-timesteps: 10000000
num-steps-per-update: 200
# SEAC
num-episodes: 5000
num-timesteps-per-episode: 100 # Models update after every n steps

#- HyperParameters - MAPPO:
share-policy: true
use-centralized-v: true
hidden-size: 64
num-mlp-hidden-layers: 3
use-popart: true
use-valuenorm: false
use-featurenorm: true
use-naive-recurrent-policy: true
use-recurrent-policy: true
num-rnn-hidden-layers: 4
rnn-data-length: 10
lr: 0.0003
critic-lr: 0.0001
adam-eps: 0.000001
num-epoch: 10
clip-range: 0.2
batch-size: 2
entropy-coef: 0.01
value-loss-coef: 1.0
max-grad-norm: 0.5
use-gae: true
gamma: 0.99
gae-lambda: 0.95


# HyperParameters - Bayesian Delegation:
#### Delegation Planner
beta: 1.3
#### Navigation Planner
alpha: 0.02
tau: 2
cap: 50
main-cap: 75